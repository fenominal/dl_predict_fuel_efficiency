{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"code.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EIdT9iu_Z4Rb"},"source":["#predict fuel efficiency"]},{"cell_type":"markdown","metadata":{"id":"FDDQoKH7XLXo"},"source":["18012011061 Patel Ayush R.  "]},{"cell_type":"code","metadata":{"id":"moB4tpEHxKB3"},"source":["# Use seaborn for pairplot\n","!pip install seaborn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1rRo8oNqZ-Rj"},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import pathlib\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gFh9ne3FZ-On"},"source":["### Get the data\n","First download the dataset."]},{"cell_type":"code","metadata":{"id":"p9kxxgzvzlyz"},"source":["dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n","dataset_path"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nslsRLh7Zss4"},"source":["Import it using pandas"]},{"cell_type":"code","metadata":{"id":"CiX2FI4gZtTt"},"source":["column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n","                'Acceleration', 'Model Year', 'Origin'] \n","raw_dataset = pd.read_csv(dataset_path, names=column_names,\n","                      na_values = \"?\", comment='\\t',\n","                      sep=\" \", skipinitialspace=True)\n","\n","dataset = raw_dataset.copy()\n","dataset.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3MWuJTKEDM-f"},"source":["### Clean the data\n","\n","The dataset contains a few unknown values. "]},{"cell_type":"code","metadata":{"id":"JEJHhN65a2VV"},"source":["dataset.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9UPN0KBHa_WI"},"source":["To keep this initial tutorial simple drop those rows. "]},{"cell_type":"code","metadata":{"id":"4ZUDosChC1UN"},"source":["dataset = dataset.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWNTD2QjBWFJ"},"source":["origin = dataset.pop('Origin')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ulXz4J7PAUzk"},"source":["dataset['USA'] = (origin == 1)*1.0\n","dataset['Europe'] = (origin == 2)*1.0\n","dataset['Japan'] = (origin == 3)*1.0\n","dataset.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cuym4yvk76vU"},"source":["### Split the data into train and test"]},{"cell_type":"code","metadata":{"id":"qn-IGhUE7_1H"},"source":["train_dataset = dataset.sample(frac=0.8,random_state=0)\n","test_dataset = dataset.drop(train_dataset.index)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J4ubs136WLNp"},"source":["### Inspect the data"]},{"cell_type":"code","metadata":{"id":"oRKO_x8gWKv-"},"source":["sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gavKO_6DWRMP"},"source":["Also look at the overall statistics:"]},{"cell_type":"code","metadata":{"id":"yi2FzC3T21jR"},"source":["train_stats = train_dataset.describe()\n","train_stats.pop(\"MPG\")\n","train_stats = train_stats.transpose()\n","train_stats"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Db7Auq1yXUvh"},"source":["### Split features from labels"]},{"cell_type":"code","metadata":{"id":"t2sluJdCW7jN"},"source":["train_labels = train_dataset.pop('MPG')\n","test_labels = test_dataset.pop('MPG')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mRklxK5s388r"},"source":["### Normalize the data\n","\n","Look again at the `train_stats` block above and note how different the ranges of each feature are."]},{"cell_type":"code","metadata":{"id":"JlC5ooJrgjQF"},"source":["def norm(x):\n","  return (x - train_stats['mean']) / train_stats['std']\n","normed_train_data = norm(train_dataset)\n","normed_test_data = norm(test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SmjdzxKzEu1-"},"source":["## The model"]},{"cell_type":"markdown","metadata":{"id":"6SWtkIjhrZwa"},"source":["### Build the model"]},{"cell_type":"code","metadata":{"id":"c26juK7ZG8j-"},"source":["def build_model():\n","  model = keras.Sequential([\n","    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train_dataset.keys())]),\n","    layers.Dense(64, activation=tf.nn.relu),\n","    layers.Dense(1)\n","  ])\n","\n","  optimizer = tf.keras.optimizers.RMSprop(0.001)\n","\n","  model.compile(loss='mean_squared_error',\n","                optimizer=optimizer,\n","                metrics=['mean_absolute_error', 'mean_squared_error'])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cGbPb-PHGbhs"},"source":["model = build_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ReAD0n6MsFK-"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-d-gBaVtGTSC"},"source":["example_batch = normed_train_data[:10]\n","example_result = model.predict(example_batch)\n","example_result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sD7qHCmNIOY0"},"source":["# Display training progress by printing a single dot for each completed epoch\n","class PrintDot(keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs):\n","    if epoch % 100 == 0: print('')\n","    print('.', end='')\n","\n","EPOCHS = 1000\n","\n","history = model.fit(\n","  normed_train_data, train_labels,\n","  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n","  callbacks=[PrintDot()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Xj91b-dymEy"},"source":["hist = pd.DataFrame(history.history)\n","hist['epoch'] = history.epoch\n","hist.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6XriGbVPh2t"},"source":["def plot_history(history):\n","  hist = pd.DataFrame(history.history)\n","  hist['epoch'] = history.epoch\n","  \n","  plt.figure()\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Mean Abs Error [MPG]')\n","  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n","           label='Train Error')\n","  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n","           label = 'Val Error')\n","  plt.ylim([0,5])\n","  plt.legend()\n","  \n","  plt.figure()\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Mean Square Error [$MPG^2$]')\n","  plt.plot(hist['epoch'], hist['mean_squared_error'],\n","           label='Train Error')\n","  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n","           label = 'Val Error')\n","  plt.ylim([0,20])\n","  plt.legend()\n","  plt.show()\n","\n","\n","plot_history(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdMZuhUgzMZ4"},"source":["model = build_model()\n","\n","# The patience parameter is the amount of epochs to check for improvement\n","early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n","\n","history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n","                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n","\n","plot_history(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jl_yNr5n1kms"},"source":["loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=0)\n","\n","print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xe7RXH3N3CWU"},"source":["test_predictions = model.predict(normed_test_data).flatten()\n","\n","plt.scatter(test_labels, test_predictions)\n","plt.xlabel('True Values [MPG]')\n","plt.ylabel('Predictions [MPG]')\n","plt.axis('equal')\n","plt.axis('square')\n","plt.xlim([0,plt.xlim()[1]])\n","plt.ylim([0,plt.ylim()[1]])\n","_ = plt.plot([-100, 100], [-100, 100])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OrkHGKZcusUo"},"source":["It looks like our model predicts reasonably well. Let's take a look at the error distribution."]},{"cell_type":"code","metadata":{"id":"f-OHX4DiXd8x"},"source":["error = test_predictions - test_labels\n","plt.hist(error, bins = 25)\n","plt.xlabel(\"Prediction Error [MPG]\")\n","_ = plt.ylabel(\"Count\")"],"execution_count":null,"outputs":[]}]}